# Deployment Documentation â€” <%= projectName %>

> **Production deployment and infrastructure guide**
> Update this document when changing deployment configuration or infrastructure.

---

## ğŸš€ Deployment Overview

**<%= projectName %>** is designed for modern deployment patterns with container orchestration, CI/CD automation, and scalable infrastructure. The application supports multiple deployment targets and follows infrastructure-as-code principles.

### Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CDN / Edge Layer                     â”‚
â”‚              (Cloudflare / Vercel Edge)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Load Balancer                        â”‚
â”‚                (Application Gateway)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Application Instances                   â”‚
â”‚            (Docker Containers / Serverless)            â”‚
<% if (docker) { %>â”‚     Frontend: Static files served via CDN              â”‚
â”‚     Backend: Hono.js API in containers                 â”‚<% } %>
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Database Layer                        â”‚
<% if (database === 'postgresql') { %>â”‚        PostgreSQL with Read/Write Replicas             â”‚<% } %>
<% if (database === 'turso') { %>â”‚         Turso Edge Database Network                    â”‚<% } %>
<% if (database === 'sqlite') { %>â”‚              SQLite with Backup Strategy               â”‚<% } %>
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<% if (docker) { %>## ğŸ³ Docker Deployment

### Container Configuration

**Multi-stage Dockerfile:**
```dockerfile
# Production-optimized container for <%= projectName %>
FROM oven/bun:1-alpine AS builder
WORKDIR /app

# Install dependencies
COPY package.json bun.lockb* ./
RUN bun install --frozen-lockfile --production=false

# Copy source and build
COPY . .
RUN bun run build

# Production image
FROM oven/bun:1-alpine AS production
WORKDIR /app

# Create non-root user for security
RUN addgroup -g 1001 -S nodejs && adduser -S bun -u 1001

# Copy built application
COPY --from=builder --chown=bun:nodejs /app/dist ./dist
COPY --from=builder --chown=bun:nodejs /app/package.json ./
COPY --from=builder --chown=bun:nodejs /app/bun.lockb* ./

# Install production dependencies only
RUN bun install --frozen-lockfile --production

# Security hardening
RUN apk --no-cache add dumb-init
USER bun

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/api/health || exit 1

EXPOSE 3000
ENTRYPOINT ["dumb-init", "--"]
CMD ["bun", "run", "start"]
```

### Docker Compose Configuration

**Development Environment:**
```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
<% if (database === 'postgresql') { %>      - DATABASE_URL=postgresql://postgres:password@db:5432/<%= projectName.toLowerCase().replace(/\s+/g, '_') %>_dev<% } %>
<% if (auth.length > 0) { %>      - BETTER_AUTH_SECRET=dev-secret-key<% } %>
    volumes:
      - .:/app
      - /app/node_modules
    depends_on:
<% if (database === 'postgresql') { %>      - db<% } %>
<% if (database === 'postgresql') { %>      - redis<% } %>
    command: bun run dev

<% if (database === 'postgresql') { %>  db:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=<%= projectName.toLowerCase().replace(/\s+/g, '_') %>_dev
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
<% } %>

volumes:
<% if (database === 'postgresql') { %>  postgres_data:
  redis_data:<% } %>
```

**Production Environment:**
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  app:
    image: <%= projectName.toLowerCase().replace(/\s+/g, '-') %>:${VERSION:-latest}
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
<% if (auth.length > 0) { %>      - BETTER_AUTH_SECRET=${BETTER_AUTH_SECRET}
      - BETTER_AUTH_URL=${BETTER_AUTH_URL}<% } %>
<% if (analytics !== 'none') { %>      - VITE_ANALYTICS_ID=${ANALYTICS_ID}<% } %>
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    networks:
      - app-network

  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - app
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

### Container Commands

```bash
# Build production image
docker build -t <%= projectName.toLowerCase().replace(/\s+/g, '-') %>:latest .

# Run development environment
docker-compose -f docker-compose.dev.yml up -d

# Run production environment
docker-compose -f docker-compose.prod.yml up -d

# Scale application instances
docker-compose -f docker-compose.prod.yml up -d --scale app=5

# View logs
docker-compose logs -f app

# Execute commands in container
docker-compose exec app bun run db:migrate

# Clean up
docker-compose down -v
```

<% } %>---

## âš™ï¸ CI/CD Pipeline

### GitHub Actions Workflow

**Complete CI/CD Pipeline:**
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Type check
        run: bun run typecheck

      - name: Lint
        run: bun run lint

<% if (unitTesting) { %>      - name: Run unit tests
        run: bun test:unit --coverage

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/coverage-final.json<% } %>

<% if (testing.includes('playwright')) { %>      - name: Install Playwright
        run: bunx playwright install --with-deps

      - name: Run E2E tests
        run: bun test:e2e

      - name: Upload E2E results
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: playwright-report
          path: playwright-report/<% } %>

  build:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment:
      name: staging
      url: https://staging.<%= projectName.toLowerCase().replace(/\s+/g, '-') %>.com

    steps:
      - name: Deploy to staging
        uses: ./.github/actions/deploy
        with:
          environment: staging
          image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
          database_url: ${{ secrets.STAGING_DATABASE_URL }}
<% if (auth.length > 0) { %>          auth_secret: ${{ secrets.STAGING_AUTH_SECRET }}<% } %>

  deploy-production:
    needs: [build, deploy-staging]
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    environment:
      name: production
      url: https://<%= projectName.toLowerCase().replace(/\s+/g, '-') %>.com

    steps:
      - name: Deploy to production
        uses: ./.github/actions/deploy
        with:
          environment: production
          image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }}
          database_url: ${{ secrets.PRODUCTION_DATABASE_URL }}
<% if (auth.length > 0) { %>          auth_secret: ${{ secrets.PRODUCTION_AUTH_SECRET }}<% } %>

      - name: Run database migrations
        run: |
          docker run --rm \
            -e DATABASE_URL="${{ secrets.PRODUCTION_DATABASE_URL }}" \
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }} \
            bun run db:migrate

      - name: Health check
        run: |
          for i in {1..30}; do
            if curl -f https://<%= projectName.toLowerCase().replace(/\s+/g, '-') %>.com/api/health; then
              echo "Health check passed"
              exit 0
            fi
            sleep 10
          done
          echo "Health check failed"
          exit 1

      - name: Rollback on failure
        if: failure()
        run: |
          # Implement rollback logic
          echo "Deployment failed, initiating rollback"
```

### Custom Deploy Action

```yaml
# .github/actions/deploy/action.yml
name: 'Deploy Application'
description: 'Deploy application to specified environment'

inputs:
  environment:
    description: 'Target environment'
    required: true
  image:
    description: 'Docker image to deploy'
    required: true
  database_url:
    description: 'Database URL'
    required: true
  auth_secret:
    description: 'Authentication secret'
    required: false

runs:
  using: 'composite'
  steps:
    - name: Deploy to ${{ inputs.environment }}
      shell: bash
      run: |
        echo "Deploying ${{ inputs.image }} to ${{ inputs.environment }}"

        # Update deployment configuration
        kubectl set image deployment/<%= projectName.toLowerCase().replace(/\s+/g, '-') %> \
          app=${{ inputs.image }} \
          --namespace=${{ inputs.environment }}

        # Wait for rollout to complete
        kubectl rollout status deployment/<%= projectName.toLowerCase().replace(/\s+/g, '-') %> \
          --namespace=${{ inputs.environment }} \
          --timeout=300s
```

---

## â˜ï¸ Cloud Platform Deployments

### Vercel Deployment

**Configuration:** `vercel.json`
```json
{
  "version": 2,
  "name": "<%= projectName.toLowerCase().replace(/\s+/g, '-') %>",
  "builds": [
    {
      "src": "src/server/index.ts",
      "use": "@vercel/node"
    },
    {
      "src": "package.json",
      "use": "@vercel/static-build",
      "config": { "distDir": "dist" }
    }
  ],
  "routes": [
    {
      "src": "/api/(.*)",
      "dest": "/src/server/index.ts"
    },
    {
      "src": "/(.*)",
      "dest": "/dist/$1"
    }
  ],
  "env": {
    "NODE_ENV": "production"
  },
  "functions": {
    "src/server/index.ts": {
      "maxDuration": 30
    }
  }
}
```

**Deployment Commands:**
```bash
# Install Vercel CLI
bun add -g vercel

# Deploy to preview
vercel

# Deploy to production
vercel --prod

# Set environment variables
vercel env add DATABASE_URL production
<% if (auth.length > 0) { %>vercel env add BETTER_AUTH_SECRET production<% } %>

# View deployments
vercel list
```

### Railway Deployment

**Configuration:** `railway.toml`
```toml
[build]
command = "bun run build"

[deploy]
startCommand = "bun run start"
healthcheckPath = "/api/health"
healthcheckTimeout = 30
restartPolicyType = "on-failure"
restartPolicyMaxRetries = 3

[environments]
[environments.production]
variables = { NODE_ENV = "production" }

[environments.staging]
variables = { NODE_ENV = "staging" }
```

### DigitalOcean App Platform

**Configuration:** `.do/app.yaml`
```yaml
name: <%= projectName.toLowerCase().replace(/\s+/g, '-') %>

services:
- name: web
  source_dir: /
  github:
    repo: your-username/<%= projectName.toLowerCase().replace(/\s+/g, '-') %>
    branch: main
  run_command: bun run start
  build_command: bun run build
  environment_slug: node-js
  instance_count: 2
  instance_size_slug: basic-xxs

  envs:
  - key: NODE_ENV
    value: production
  - key: DATABASE_URL
    value: ${db.DATABASE_URL}
<% if (auth.length > 0) { %>  - key: BETTER_AUTH_SECRET
    value: ${auth_secret.value}<% } %>

  health_check:
    http_path: /api/health

<% if (database === 'postgresql') { %>databases:
- name: db
  engine: PG
  version: "15"
  size: basic-xs<% } %>
```

### AWS ECS Deployment

**Task Definition:**
```json
{
  "family": "<%= projectName.toLowerCase().replace(/\s+/g, '-') %>",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "256",
  "memory": "512",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "<%= projectName.toLowerCase().replace(/\s+/g, '-') %>",
      "image": "ACCOUNT.dkr.ecr.REGION.amazonaws.com/<%= projectName.toLowerCase().replace(/\s+/g, '-') %>:latest",
      "portMappings": [
        {
          "containerPort": 3000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "NODE_ENV",
          "value": "production"
        }
      ],
      "secrets": [
        {
          "name": "DATABASE_URL",
          "valueFrom": "/app/database-url"
        }<% if (auth.length > 0) { %>,
        {
          "name": "BETTER_AUTH_SECRET",
          "valueFrom": "/app/auth-secret"
        }<% } %>
      ],
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      },
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/aws/ecs/<%= projectName.toLowerCase().replace(/\s+/g, '-') %>",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

---

## ğŸ”’ Environment Configuration

### Environment Variables

**Required Variables:**
```bash
# Application
NODE_ENV=production
PORT=3000

<% if (database === 'postgresql') { %># PostgreSQL Database
DATABASE_URL=postgresql://user:password@host:port/database
DATABASE_POOL_SIZE=20
DATABASE_TIMEOUT=30000<% } %>

<% if (database === 'turso') { %># Turso Database
DATABASE_URL=libsql://database-url.turso.io
DATABASE_AUTH_TOKEN=your-auth-token<% } %>

<% if (database === 'sqlite') { %># SQLite Database
DATABASE_URL=./production.db<% } %>

<% if (auth.length > 0) { %># Authentication
BETTER_AUTH_SECRET=your-super-secret-key-here
BETTER_AUTH_URL=https://your-domain.com

<% auth.forEach(provider => { if (['github', 'google', 'discord', 'microsoft'].includes(provider)) { %># <%= provider.charAt(0).toUpperCase() + provider.slice(1) %> OAuth
<%= provider.toUpperCase() %>_CLIENT_ID=your-client-id
<%= provider.toUpperCase() %>_CLIENT_SECRET=your-client-secret
<% }}) %><% } %>

<% if (analytics === 'google') { %># Analytics
VITE_GA_ID=G-XXXXXXXXXX<% } %>
<% if (analytics === 'posthog') { %># PostHog Analytics
VITE_POSTHOG_KEY=your-posthog-key
VITE_POSTHOG_HOST=https://app.posthog.com<% } %>

<% if (errorTracking === 'sentry') { %># Error Tracking
VITE_SENTRY_DSN=https://your-dsn@sentry.io/project
SENTRY_ORG=your-org
SENTRY_PROJECT=your-project<% } %>
<% if (errorTracking === 'bugsnag') { %>VITE_BUGSNAG_API_KEY=your-bugsnag-key<% } %>

# Security
CORS_ORIGIN=https://your-domain.com
RATE_LIMIT_WINDOW=900000
RATE_LIMIT_MAX=100
```

### Secret Management

**Using AWS Systems Manager:**
```bash
# Store secrets
aws ssm put-parameter \
  --name "/app/database-url" \
  --value "postgresql://..." \
  --type "SecureString"

<% if (auth.length > 0) { %>aws ssm put-parameter \
  --name "/app/auth-secret" \
  --value "your-secret-key" \
  --type "SecureString"<% } %>

# Retrieve secrets in deployment
export DATABASE_URL=$(aws ssm get-parameter \
  --name "/app/database-url" \
  --with-decryption \
  --query "Parameter.Value" \
  --output text)
```

**Using Kubernetes Secrets:**
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: <%= projectName.toLowerCase().replace(/\s+/g, '-') %>-secrets
type: Opaque
stringData:
  database-url: "postgresql://..."
<% if (auth.length > 0) { %>  auth-secret: "your-secret-key"<% } %>
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: <%= projectName.toLowerCase().replace(/\s+/g, '-') %>
spec:
  template:
    spec:
      containers:
      - name: app
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: <%= projectName.toLowerCase().replace(/\s+/g, '-') %>-secrets
              key: database-url
<% if (auth.length > 0) { %>        - name: BETTER_AUTH_SECRET
          valueFrom:
            secretKeyRef:
              name: <%= projectName.toLowerCase().replace(/\s+/g, '-') %>-secrets
              key: auth-secret<% } %>
```

---

## ğŸ“Š Monitoring & Observability

### Health Checks

**API Health Endpoint:**
```typescript
// src/server/routes/health.ts
import { Hono } from 'hono'
<% if (database !== 'none') { %>import { db } from '@/db'<% } %>

const health = new Hono()

health.get('/health', async (c) => {
  const checks = {
    status: 'healthy',
    timestamp: new Date().toISOString(),
    version: process.env.npm_package_version || '1.0.0',
    environment: process.env.NODE_ENV,
    checks: {
      api: 'healthy',
<% if (database !== 'none') { %>      database: await checkDatabase(),<% } %>
      memory: checkMemory(),
      disk: await checkDisk(),
    }
  }

  const isHealthy = Object.values(checks.checks).every(status => status === 'healthy')

  return c.json(checks, isHealthy ? 200 : 503)
})

<% if (database !== 'none') { %>async function checkDatabase(): Promise<string> {
  try {
    await db.execute('SELECT 1')
    return 'healthy'
  } catch (error) {
    console.error('Database health check failed:', error)
    return 'unhealthy'
  }
}
<% } %>

function checkMemory(): string {
  const used = process.memoryUsage()
  const memoryUsagePercent = (used.heapUsed / used.heapTotal) * 100
  return memoryUsagePercent < 90 ? 'healthy' : 'warning'
}

async function checkDisk(): Promise<string> {
  try {
    const fs = await import('fs/promises')
    const stats = await fs.statSync('.')
    return 'healthy'
  } catch (error) {
    return 'unhealthy'
  }
}

export default health
```

### Logging Configuration

**Structured Logging:**
```typescript
// src/lib/logger.ts
import { createLogger, format, transports } from 'winston'

export const logger = createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: format.combine(
    format.timestamp(),
    format.errors({ stack: true }),
    format.json()
  ),
  defaultMeta: {
    service: '<%= projectName.toLowerCase().replace(/\s+/g, '-') %>',
    version: process.env.npm_package_version,
    environment: process.env.NODE_ENV
  },
  transports: [
    new transports.Console({
      format: process.env.NODE_ENV === 'development'
        ? format.combine(format.colorize(), format.simple())
        : format.json()
    })
  ]
})

// Request logging middleware
export const loggerMiddleware = (c: any, next: any) => {
  const start = Date.now()

  return next().finally(() => {
    const duration = Date.now() - start
    logger.info('HTTP Request', {
      method: c.req.method,
      url: c.req.url,
      status: c.res.status,
      duration,
      userAgent: c.req.header('User-Agent'),
      ip: c.req.header('CF-Connecting-IP') || c.req.header('X-Forwarded-For')
    })
  })
}
```

### Metrics & Alerting

**Prometheus Metrics:**
```typescript
// src/lib/metrics.ts
import { register, Counter, Histogram, Gauge } from 'prom-client'

// HTTP metrics
export const httpRequestsTotal = new Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status_code']
})

export const httpRequestDuration = new Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route'],
  buckets: [0.1, 0.5, 1, 2, 5]
})

<% if (database !== 'none') { %>// Database metrics
export const dbConnectionsActive = new Gauge({
  name: 'database_connections_active',
  help: 'Number of active database connections'
})

export const dbQueryDuration = new Histogram({
  name: 'database_query_duration_seconds',
  help: 'Duration of database queries in seconds',
  buckets: [0.001, 0.01, 0.1, 0.5, 1, 2]
})
<% } %>

// Application metrics
export const memoryUsage = new Gauge({
  name: 'nodejs_memory_usage_bytes',
  help: 'Node.js memory usage in bytes',
  labelNames: ['type']
})

// Collect default metrics
register.collectDefaultMetrics()

// Update memory metrics periodically
setInterval(() => {
  const usage = process.memoryUsage()
  memoryUsage.set({ type: 'heap_used' }, usage.heapUsed)
  memoryUsage.set({ type: 'heap_total' }, usage.heapTotal)
  memoryUsage.set({ type: 'rss' }, usage.rss)
}, 5000)
```

---

## ğŸ”„ Database Deployment

<% if (database === 'postgresql') { %>### PostgreSQL Production Setup

**Connection Configuration:**
```typescript
// src/db/pool.ts
import { Pool } from 'pg'

export const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
  max: 20, // Maximum pool size
  min: 2,  // Minimum pool size
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 10000,
  query_timeout: 60000,
})

// Health monitoring
pool.on('error', (err) => {
  logger.error('Unexpected error on idle client', err)
  process.exit(-1)
})

pool.on('connect', () => {
  logger.info('Connected to PostgreSQL')
})
```

**Migration Scripts:**
```typescript
// scripts/migrate.ts
import { Pool } from 'pg'
import { drizzle } from 'drizzle-orm/node-postgres'
import { migrate } from 'drizzle-orm/node-postgres/migrator'

async function runMigrations() {
  const pool = new Pool({
    connectionString: process.env.DATABASE_URL,
    ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
  })

  const db = drizzle(pool)

  try {
    await migrate(db, { migrationsFolder: 'drizzle' })
    console.log('Migrations completed successfully')
  } catch (error) {
    console.error('Migration failed:', error)
    process.exit(1)
  } finally {
    await pool.end()
  }
}

runMigrations()
```

**Backup Strategy:**
```bash
#!/bin/bash
# scripts/backup-db.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="<%= projectName.toLowerCase().replace(/\s+/g, '_') %>_${DATE}.sql"

# Create backup
pg_dump $DATABASE_URL > $BACKUP_FILE

# Compress backup
gzip $BACKUP_FILE

# Upload to S3
aws s3 cp ${BACKUP_FILE}.gz s3://your-backup-bucket/database/

# Clean up local file
rm ${BACKUP_FILE}.gz

# Keep only last 7 days of backups
aws s3api list-objects-v2 --bucket your-backup-bucket --prefix database/ \
  --query 'sort_by(Contents, &LastModified)[:-7].[Key]' --output text | \
  xargs -I {} aws s3 rm s3://your-backup-bucket/{}
```
<% } %>

<% if (database === 'turso') { %>### Turso Edge Database

**Production Configuration:**
```typescript
// src/db/turso.ts
import { createClient } from '@libsql/client'
import { drizzle } from 'drizzle-orm/libsql'

export const tursoClient = createClient({
  url: process.env.DATABASE_URL!,
  authToken: process.env.DATABASE_AUTH_TOKEN!,
})

export const db = drizzle(tursoClient)

// Connection health monitoring
export async function checkTursoHealth() {
  try {
    await db.execute('SELECT 1')
    return true
  } catch (error) {
    logger.error('Turso health check failed:', error)
    return false
  }
}
```

**Migration Deployment:**
```bash
# Install Turso CLI
curl -sSfL https://get.tur.so/install.sh | bash

# Apply migrations to production
turso db shell your-db-name < drizzle/migrations/001_initial.sql

# Or use automated migration in CI/CD
npm run db:migrate
```
<% } %>

<% if (database === 'sqlite') { %>### SQLite Production Setup

**File-based Configuration:**
```typescript
// src/db/sqlite.ts
import Database from 'better-sqlite3'
import { drizzle } from 'drizzle-orm/better-sqlite3'

const sqlite = new Database(process.env.DATABASE_URL || './production.db')

// Enable WAL mode for better concurrency
sqlite.pragma('journal_mode = WAL')
sqlite.pragma('synchronous = NORMAL')
sqlite.pragma('cache_size = 1000000')
sqlite.pragma('foreign_keys = ON')

export const db = drizzle(sqlite)

// Graceful shutdown
process.on('SIGINT', () => {
  sqlite.close()
  process.exit(0)
})
```

**Backup Strategy:**
```bash
#!/bin/bash
# scripts/backup-sqlite.sh

DATE=$(date +%Y%m%d_%H%M%S)
DB_FILE="${DATABASE_URL:-./production.db}"
BACKUP_FILE="<%= projectName.toLowerCase().replace(/\s+/g, '_') %>_${DATE}.db"

# Create backup using SQLite's backup command
sqlite3 $DB_FILE ".backup $BACKUP_FILE"

# Compress backup
gzip $BACKUP_FILE

# Upload to storage
aws s3 cp ${BACKUP_FILE}.gz s3://your-backup-bucket/database/

# Clean up
rm ${BACKUP_FILE}.gz
```
<% } %>

---

## ğŸ›¡ï¸ Security & Compliance

### SSL/TLS Configuration

**Nginx SSL Setup:**
```nginx
# nginx/nginx.conf
server {
    listen 80;
    server_name <%= projectName.toLowerCase().replace(/\s+/g, '-') %>.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name <%= projectName.toLowerCase().replace(/\s+/g, '-') %>.com;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;

    # Security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload";

    location / {
        proxy_pass http://app:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### Security Scanning

**Container Security:**
```yaml
# .github/workflows/security.yml
name: Security Scan

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Build Docker image
        run: docker build -t temp-image .

      - name: Scan Docker image
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'temp-image'
          format: 'sarif'
          output: 'trivy-image.sarif'
```

### GDPR Compliance

**Data Processing Setup:**
```typescript
// src/lib/gdpr.ts
export interface DataProcessingRecord {
  userId: string
  dataType: string
  purpose: string
  lawfulBasis: string
  retention: number
  processor?: string
}

export class GDPRCompliance {
  static async recordDataProcessing(record: DataProcessingRecord) {
    // Log data processing activities
    logger.info('Data processing recorded', {
      ...record,
      timestamp: new Date().toISOString()
    })
  }

  static async handleDataSubjectRequest(
    type: 'access' | 'rectification' | 'erasure' | 'portability',
    userId: string
  ) {
    switch (type) {
      case 'access':
        return await this.exportUserData(userId)
      case 'erasure':
        return await this.deleteUserData(userId)
      // ... other cases
    }
  }

  private static async exportUserData(userId: string) {
    // Export all user data in structured format
  }

  private static async deleteUserData(userId: string) {
    // Anonymize or delete user data according to retention policies
  }
}
```

---

## ğŸ“š Deployment Checklists

### Pre-deployment Checklist

**Code Quality:**
- [ ] All tests passing
- [ ] Code coverage >80%
- [ ] No critical security vulnerabilities
- [ ] Performance benchmarks met
- [ ] Documentation updated

**Configuration:**
- [ ] Environment variables configured
- [ ] Database migrations ready
- [ ] SSL certificates valid
- [ ] CDN configuration updated
- [ ] Monitoring alerts configured

**Security:**
- [ ] Secrets properly managed
- [ ] CORS policy configured
- [ ] Rate limiting enabled
- [ ] Security headers configured
- [ ] GDPR compliance verified

### Post-deployment Checklist

**Verification:**
- [ ] Health checks passing
- [ ] All endpoints responding
- [ ] Database connectivity confirmed
- [ ] Authentication working
- [ ] External integrations functional

**Monitoring:**
- [ ] Metrics collection active
- [ ] Log aggregation working
- [ ] Alert rules configured
- [ ] Error tracking functional
- [ ] Performance monitoring active

**Rollback Plan:**
- [ ] Previous version available
- [ ] Rollback procedure tested
- [ ] Database rollback plan ready
- [ ] Emergency contacts notified
- [ ] Incident response plan reviewed

---

*Last Updated: <%= new Date().toLocaleDateString() %>*
*Generated by KareTech Stack*